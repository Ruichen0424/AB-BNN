{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29297ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import amp\n",
    "from scipy.io import savemat\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from Network.ReActNet_18_Qaw import *\n",
    "from Network.ReActNet_A_Qaw import *\n",
    "from Network.utils import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ba8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begin_epoch = 0\n",
    "Max_epoch = 256\n",
    "Learning_rate = 1e-3\n",
    "Weight_decay = 0\n",
    "Momentum = 0.9\n",
    "Top_k = 5\n",
    "AMP = False\n",
    "\n",
    "Dataset_path = '/ssd/Datasets/ImageNet/'\n",
    "Batch_size = 256\n",
    "Workers = 28\n",
    "Targetnum = 1000\n",
    "\n",
    "Test_every_iteration = None\n",
    "Name_suffix = '_step2'\n",
    "Savemodel_path = './savemodels/'\n",
    "Record_path = './recorddata/'\n",
    "if not os.path.exists(Savemodel_path):\n",
    "    os.mkdir(Savemodel_path)\n",
    "if not os.path.exists(Record_path):\n",
    "    os.mkdir(Record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed_ = 2023\n",
    "torch.manual_seed(_seed_)\n",
    "np.random.seed(_seed_)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0)),\n",
    "    Lighting(0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([                      \n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "Train_data = datasets.ImageFolder(root=Dataset_path+'train', transform=transform_train)\n",
    "Test_data = datasets.ImageFolder(root=Dataset_path+'val', transform=transform_test)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=Train_data,\n",
    "    batch_size=Batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Workers, \n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=Test_data,\n",
    "    batch_size=Batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Workers, \n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teacher = torchvision.models.__dict__['resnet34'](weights = torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "model_teacher = nn.DataParallel(model_teacher).cuda()\n",
    "for p in model_teacher.parameters():\n",
    "    p.requires_grad = False\n",
    "model_teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18(num_classes=Targetnum, imagenet=True)\n",
    "# net = Reactnet(num_classes=Targetnum, imagenet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af79190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = nn.DataParallel(net).cuda()\n",
    "max_test_acc = 0.\n",
    "if Begin_epoch!=0:\n",
    "    net.load_state_dict(torch.load(Savemodel_path + f'epoch{Begin_epoch-1}{Name_suffix}.h5'))\n",
    "    max_test_acc = np.load(Savemodel_path + f'max_acc{Name_suffix}.npy')\n",
    "    max_test_acc = max_test_acc.item()\n",
    "else:\n",
    "    net.load_state_dict(torch.load(Savemodel_path + f'max_acc_step1.h5'))\n",
    "\n",
    "scaler = amp.GradScaler() if AMP else None\n",
    "Test_top1 = []\n",
    "Test_topk = []\n",
    "Test_lossall = []\n",
    "Epoch_list = []\n",
    "Iteration_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_train = DistributionLoss()\n",
    "criterion_test = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params' : net.parameters(), 'weight_decay' : Weight_decay, 'initial_lr': Learning_rate}],\n",
    "    lr = Learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step : (1.0-step/Max_epoch), last_epoch=Begin_epoch-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1151c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net, max_test_acc, data_loader=test_data_loader, criterion=criterion_test, epoch=None, iteration=None, record=True):\n",
    "    net.eval()\n",
    "    test_samples = 0\n",
    "    test_loss = 0\n",
    "    test_acc_top1 = 0\n",
    "    test_acc_topk = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(data_loader):\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            label_onehot = F.one_hot(label, Targetnum).float()\n",
    "            \n",
    "            out_fr = net(img)\n",
    "            loss = criterion(out_fr, label)\n",
    "                \n",
    "            test_samples += label.numel()\n",
    "            test_loss += loss.item() * label.numel()\n",
    "\n",
    "            test_acc_top1 += (out_fr.argmax(1) == label).float().sum().item()\n",
    "            _, pred = out_fr.topk(Top_k, 1, True, True)\n",
    "            test_acc_topk += torch.eq(pred, label.view(-1,1)).float().sum().item()\n",
    "    \n",
    "    test_loss /= test_samples\n",
    "    test_acc_top1 /= test_samples\n",
    "    test_acc_topk /= test_samples\n",
    "\n",
    "    if test_acc_top1 >= max_test_acc:\n",
    "        max_test_acc = test_acc_top1\n",
    "        torch.save(net.state_dict(), Savemodel_path + f'max_acc{Name_suffix}.h5')\n",
    "        np.save(Savemodel_path + f'max_acc{Name_suffix}.npy', np.array(max_test_acc))\n",
    "\n",
    "    if record:\n",
    "        assert epoch is not None, \"epoch is None!\"\n",
    "        assert iteration is not None, \"iteration is None!\"\n",
    "        \n",
    "        Epoch_list.append(epoch+1)\n",
    "        Iteration_list.append(iteration+1)\n",
    "        Test_top1.append(test_acc_top1)\n",
    "        Test_topk.append(test_acc_topk)\n",
    "        Test_lossall.append(test_loss)\n",
    "\n",
    "        record_data = np.array([Epoch_list, Iteration_list, Test_top1, Test_topk, Test_lossall]).T\n",
    "        mdic = {f'Record_data':record_data, f'Record_meaning':['Epoch_list', 'Iteration_list', 'Test_top1', f'Test_top{Top_k}', 'Test_loss']}\n",
    "\n",
    "        savemat(Record_path + f'Test_{Begin_epoch}_{epoch}{Name_suffix}.mat',mdic)\n",
    "        if os.path.exists(Record_path + f'Test_{Begin_epoch}_{epoch-1}{Name_suffix}.mat'):\n",
    "            os.remove(Record_path + f'Test_{Begin_epoch}_{epoch-1}{Name_suffix}.mat')\n",
    "\n",
    "    return test_loss, test_acc_top1, test_acc_topk, max_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, max_test_acc, epoch, data_loader=train_data_loader, optimizer=optimizer, criterion=criterion_train, scaler=scaler, record=True):\n",
    "    train_samples = 0\n",
    "    train_loss = 0\n",
    "    train_acc_top1 = 0\n",
    "    train_acc_topk = 0\n",
    "    \n",
    "    for i, (img, label) in enumerate(tqdm(data_loader)):\n",
    "        net.train()\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        label_onehot = F.one_hot(label, Targetnum).float()\n",
    "        \n",
    "        if AMP:\n",
    "            with amp.autocast():\n",
    "                out_fr = net(img)\n",
    "                out_teacher = model_teacher(img)\n",
    "                loss = criterion(out_fr, out_teacher)\n",
    "        else:\n",
    "            out_fr = net(img)\n",
    "            out_teacher = model_teacher(img)\n",
    "            loss = criterion(out_fr, out_teacher)\n",
    "            \n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "\n",
    "        train_acc_top1 += (out_fr.argmax(1) == label).float().sum().item()\n",
    "        _, pred = out_fr.topk(Top_k, 1, True, True)\n",
    "        train_acc_topk += torch.eq(pred, label.view(-1,1)).float().sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "            parameters_list = []\n",
    "            for name, p in net.named_parameters():\n",
    "                if not 'fc' in name:\n",
    "                    parameters_list.append(p)\n",
    "            adaptive_clip_grad(parameters_list, clip_factor=0.02)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        if Test_every_iteration is not None:\n",
    "            if (i+1) % Test_every_iteration == 0:\n",
    "                test_loss, test_acc_top1, test_acc_topk, max_test_acc = test_model(net, max_test_acc, epoch=epoch, iteration=i, record=record)\n",
    "                print(f'Test_loss: {test_loss:.4f}, Test_acc_top1: {test_acc_top1:.4f}, Test_acc_top{Top_k}: {test_acc_topk:.4f}, Max_test_acc: {max_test_acc:.4f}')\n",
    "    \n",
    "    train_loss /= train_samples\n",
    "    train_acc_top1 /= train_samples\n",
    "    train_acc_topk /= train_samples\n",
    "\n",
    "    test_loss, test_acc_top1, test_acc_topk, max_test_acc = test_model(net, max_test_acc, epoch=epoch, iteration=i, record=record)\n",
    "        \n",
    "    return train_loss, train_acc_top1, train_acc_topk, test_loss, test_acc_top1, test_acc_topk, max_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8d52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(Begin_epoch, Max_epoch):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc_top1, train_acc_topk, test_loss, test_acc_top1, test_acc_topk, max_test_acc = train_model(net, max_test_acc, epoch)\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(f'''epoch={epoch}, train_acc_top1={train_acc_top1:.4f}, train_acc_top{Top_k}={train_acc_topk:.4f}, train_loss={train_loss:.4f}, test_top1={test_acc_top1:.4f}, test_top{Top_k}={test_acc_topk:.4f}, test_loss={test_loss:.4f}, max_test_acc={max_test_acc:.4f}, total_time={(time.time() - start_time):.4f}, LR={lr:.8f}''')\n",
    "    \n",
    "    torch.save(net.state_dict(), Savemodel_path + f'epoch{epoch}{Name_suffix}.h5')\n",
    "    if os.path.exists(Savemodel_path + f'epoch{epoch-1}{Name_suffix}.h5'):\n",
    "        os.remove(Savemodel_path + f'epoch{epoch-1}{Name_suffix}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e69091",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(Savemodel_path + f'max_acc{Name_suffix}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998ffd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Confusion_Matrix = torch.zeros((Targetnum, Targetnum))\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for img, label in tqdm(test_data_loader):\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        out_fr = net(img)\n",
    "        guess = out_fr.argmax(1)\n",
    "        for j in range(len(label)):\n",
    "            Confusion_Matrix[label[j],guess[j]] += 1\n",
    "acc = Confusion_Matrix.diag()\n",
    "acc = acc.sum()/Confusion_Matrix.sum()\n",
    "print(f'Confusion_Matrix = {Confusion_Matrix}')\n",
    "print(f'acc = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
